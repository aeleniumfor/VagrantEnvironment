Vagrant.configure("2") do |config|
  config.vm.box = "centos/7"
  config.vm.provision :shell, inline: $script

  config.vm.define "master" do |server|
    server.vm.network "private_network", ip: "192.168.56.101"
    server.vm.provision :shell, inline: $scriptMaster 
    server.vm.hostname = "master"
  end

  config.vm.define "node1" do |server|
    server.vm.network "private_network", ip: "192.168.56.102"
    server.vm.hostname = "node1"
  end


  config.vm.provider "virtualbox" do |vb|
    # 割り当てるメモリー(MB)
    vb.memory = 2000
    # CPUの数
    vb.cpus = 2
  end

end


$script = <<END
yum -y update
yum -y install git vim wget
systemctl stop firewalld
systemctl disable firewalld


setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config


# Install Docker CE
## Set up the repository
### Install required packages.
yum install -y yum-utils device-mapper-persistent-data lvm2

### Add Docker repository.
yum-config-manager \
  --add-repo \
  https://download.docker.com/linux/centos/docker-ce.repo

## Install Docker CE.
yum -y update && yum -y install docker-ce-18.06.2.ce

## Create /etc/docker directory.
mkdir /etc/docker

# Setup daemon.
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

mkdir -p /etc/systemd/system/docker.service.d

# Restart Docker
systemctl daemon-reload && systemctl restart docker && systemctl enable docker


cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kube*
EOF


yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable --now kubelet


cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system

IPADDR=$(ip a show eth1 | grep inet | grep -v inet6 | awk '{print $2}' | cut -f1 -d/)
sed -i "/KUBELET_EXTRA_ARGS=/c\KUBELET_EXTRA_ARGS=--node-ip=$IPADDR" /etc/sysconfig/kubelet
# kubeletを再起動
systemctl daemon-reload
systemctl restart kubelet

sudo usermod -aG docker vagrant
sudo swapoff -a
sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab
END


$scriptMaster = <<END

## kubeadam init
## create kubernetes master node 
IPADDR=$(ip a show eth1 | grep inet | grep -v inet6 | awk '{print $2}' | cut -f1 -d/)
HOSTNAME=$(hostname -s)
kubeadm init --apiserver-advertise-address=$IPADDR --apiserver-cert-extra-sans=$IPADDR --node-name $HOSTNAME --pod-network-cidr=192.168.0.0/16

## useable kubectl for root user
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config


## useable kubectl for vagrant user
sudo --user=vagrant mkdir -p /home/vagrant/.kube
cp -i /etc/kubernetes/admin.conf /home/vagrant/.kube/config
chown $(id -u vagrant):$(id -g vagrant) /home/vagrant/.kube/config

## setting network
export KUBECONFIG=/etc/kubernetes/admin.conf
kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml
kubectl apply -f https://docs.projectcalico.org/v3.8/manifests/calico.yaml

## create join kubernetes cluster command
kubeadm token create --print-join-command > /etc/kubeadm_join_cmd.sh

END

# vagrant halt && vagrant destroy -f && vagrant up
# kubeadm init --apiserver-advertise-address=192.168.1.101 --pod-network-cidr=10.244.0.0/16
# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
# kubectl apply -f kube-flannel.yml
# sudo kubeadm join 192.168.56.101:6443 --token ruubhl.8qkpgqtb1ki32ibc     --discovery-token-ca-cert-hash sha256:9c3b6ce1cee80681fd4cc13465ff46f082bc01a4d584767895f5e1ec2f7b65cd